{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/likithpala7/real-fake-detector/blob/main/train_mc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZugPr9GJAST"
      },
      "outputs": [],
      "source": [
        "!pip install ftfy regex tqdm\n",
        "!pip install git+https://github.com/openai/CLIP.git\n",
        "!pip install peft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fp-GoVH8JRrY",
        "outputId": "3f8eb215-039c-43dd-b8d4-fd5fd87128cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Hs2ZMb4fJZA4"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "import json\n",
        "import torch\n",
        "import clip\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import json\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.ops import sigmoid_focal_loss\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple\n",
        "import pandas as pd\n",
        "from copy import deepcopy\n",
        "from tqdm import tqdm\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vWV2YZ0uK4DY"
      },
      "outputs": [],
      "source": [
        "!unzip -q drive/MyDrive/GenImage/imagenet_ai_holdout.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GfgORd39K6fh"
      },
      "outputs": [],
      "source": [
        "!rm imagenet_ai_holdout/ADM/train/115_adm_156.PNG\n",
        "!rm imagenet_ai_holdout/BigGAN/train/116_biggan_00098.png\n",
        "!rm imagenet_ai_holdout/BigGAN/train/116_biggan_00107.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZiR_RfE-JbDI"
      },
      "outputs": [],
      "source": [
        "label_dict = {model: i for i, model in\n",
        "               enumerate(sorted(os.listdir('imagenet_ai_holdout')))}\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "\n",
        "    def get_dataset(self, d_type):\n",
        "\n",
        "        data = []\n",
        "\n",
        "        for dataset in os.listdir('imagenet_ai_holdout'):\n",
        "\n",
        "            imgs = os.listdir(os.path.join('imagenet_ai_holdout', dataset, d_type))\n",
        "\n",
        "            data.extend([os.path.join('imagenet_ai_holdout', dataset, d_type, img)\n",
        "                         for img in imgs])\n",
        "\n",
        "\n",
        "        return data\n",
        "\n",
        "\n",
        "    def __init__(self, d_type='train'):\n",
        "\n",
        "\n",
        "       self.data = self.get_dataset(d_type)\n",
        "\n",
        "       _, self.preprocess = clip.load('ViT-B/32', device=device)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        # Get the question and answer at the idx\n",
        "        img_path = self.data[idx]\n",
        "\n",
        "        model_type = img_path.split(os.path.sep)[1]\n",
        "        label = torch.tensor(label_dict[model_type]).to(device)\n",
        "\n",
        "        # Concatenate images into a single tensor\n",
        "        img = self.preprocess(Image.open(img_path)).to(device)\n",
        "\n",
        "        return img, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DLAliDOUKs9N"
      },
      "outputs": [],
      "source": [
        "CLIP_HIDDEN_STATE = 512\n",
        "\n",
        "def print_trainable_parameters(model):\n",
        "\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "\n",
        "    print(\n",
        "        f\"Trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )\n",
        "\n",
        "\n",
        "class CLIPModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.clip_model, _ = clip.load('ViT-B/32', device=device)\n",
        "\n",
        "        # Freeze the CLIP model\n",
        "        for param in self.clip_model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Classification head\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(CLIP_HIDDEN_STATE, CLIP_HIDDEN_STATE//2),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(CLIP_HIDDEN_STATE//2, len(label_dict)),\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.clip_model.encode_image(x).float()\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kDaQyvA3K8F5"
      },
      "outputs": [],
      "source": [
        "Config = namedtuple('Instance', ['batch_size', 'learning_rate',\n",
        "                                 'weight_decay', 'num_workers',\n",
        "                                 'epochs', 'load_checkpoint',\n",
        "                                 'file_checkpoint'])\n",
        "\n",
        "config = Config(\n",
        "    batch_size = 512,\n",
        "    learning_rate = 1e-3,\n",
        "    weight_decay = 0.05,\n",
        "    num_workers = 0,\n",
        "    epochs = 5,\n",
        "    load_checkpoint = False,\n",
        "    file_checkpoint = '',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzS1hkELK91S",
        "outputId": "20da3061-a15d-4fb5-fcee-0f95382c50ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All model checkpoints and training stats will be saved in drive/MyDrive/GenImage/results/20240504-214639\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------- EPOCH 0 ---------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|â–‹         | 35/527 [03:51<53:18,  6.50s/it]"
          ]
        }
      ],
      "source": [
        "def save_model(model, model_name):\n",
        "    # Save the model into the designated folder\n",
        "    path = os.path.join('drive', 'MyDrive', 'GenImage', 'results', timestr, model_name + '.pth')\n",
        "    torch.save(model, path)\n",
        "\n",
        "\n",
        "def val_model(dloader, val_model):\n",
        "    val_model.eval()\n",
        "    val_loss = 0\n",
        "    val_accuracy = 0\n",
        "    predictions, label_list = [], []\n",
        "\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "      for idx, (inputs, labels) in tqdm(enumerate(dloader), total=len(dloader)):\n",
        "\n",
        "          logits = val_model(inputs)\n",
        "\n",
        "          loss = criterion(logits, labels)\n",
        "\n",
        "          val_loss = loss.item()\n",
        "\n",
        "          val_acc, preds = compute_accuracy(logits, labels)\n",
        "          val_accuracy += val_acc\n",
        "          predictions.extend(preds.tolist())\n",
        "          label_list.extend(labels.tolist())\n",
        "\n",
        "    plot_confusion_matrix(predictions, label_list)\n",
        "    return val_loss / len(val_dataloader), val_accuracy / len(val_dataloader)\n",
        "\n",
        "\n",
        "def save_stats(train_loss, val_loss, train_acc, val_acc, epochs,\n",
        "               lr, train_accs, val_accs):\n",
        "    stats_dict = {\n",
        "        'losses': losses,\n",
        "        'val losses': val_losses,\n",
        "        'training accuracies': train_accs,\n",
        "        'val accuracies': val_accs,\n",
        "        'min train loss': train_loss,\n",
        "        'min val loss': val_loss,\n",
        "        'max train acc': train_acc,\n",
        "        'max val acc': val_acc,\n",
        "        'epochs': epochs,\n",
        "        'learning rate': lr,\n",
        "    }\n",
        "\n",
        "    fname = f'stats.json'\n",
        "\n",
        "    # Save stats into checkpoint\n",
        "    with open(os.path.join('drive', 'MyDrive', 'GenImage', 'results', timestr, fname), 'w') as f:\n",
        "        json.dump(stats_dict, f)\n",
        "\n",
        "def compute_accuracy(logits, labels):\n",
        "\n",
        "    preds = torch.argmax(F.softmax(logits, dim=-1), dim=-1)\n",
        "    correct = (preds == labels).sum().item()\n",
        "    total = labels.size(0)\n",
        "    return correct / total, preds\n",
        "\n",
        "def plot_confusion_matrix(predictions, labels):\n",
        "\n",
        "    # Define the class names and order\n",
        "    classes = sorted(os.listdir('imagenet_ai_holdout'))\n",
        "\n",
        "    # Create the confusion matrix using sklearn\n",
        "    cm = confusion_matrix(labels, predictions)\n",
        "\n",
        "    # Calculate row-wise sums to normalize the confusion matrix\n",
        "    row_sums = cm.sum(axis=1, keepdims=True)\n",
        "    normalized_cm = cm / row_sums.astype(float)\n",
        "\n",
        "    # Convert normalized confusion matrix to DataFrame with named rows and columns\n",
        "    normalized_cm_df = pd.DataFrame(normalized_cm, index=classes, columns=classes)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.set(font_scale=1.4)  # Adjust to fit labels properly\n",
        "\n",
        "    # Create a heatmap plot\n",
        "    sns.heatmap(normalized_cm_df, annot=True, fmt='.2f', cmap='Blues', cbar=False,\n",
        "                annot_kws={\"size\": 16}, linewidths=1, linecolor='black')\n",
        "\n",
        "    plt.title('Normalized Confusion Matrix')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.yticks(rotation=0)  # Ensure correct orientation of row labels\n",
        "\n",
        "    # Adjust layout to ensure all borders are visible\n",
        "    plt.tight_layout(pad=1.0)\n",
        "\n",
        "    img_num = len(os.listdir(os.path.join('drive', 'MyDrive', 'GenImage',\n",
        "                                          'results', timestr, 'Confusion Matrices')))\n",
        "    fname = f'cf_{img_num}.png'\n",
        "    plt.savefig(os.path.join('drive', 'MyDrive', 'GenImage', 'results', timestr, 'Confusion Matrices', fname))\n",
        "\n",
        "\n",
        "def plot_loss(training_loss, val_loss):\n",
        "    num_epochs = len(training_loss)\n",
        "\n",
        "    plt.clf()\n",
        "    plt.plot(range(1, num_epochs + 1), training_loss, label='Training Loss')\n",
        "    plt.plot(range(1, num_epochs + 1), val_loss, label='Validation Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Num epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    fname = f'loss.png'\n",
        "    plt.savefig(os.path.join('drive', 'MyDrive', 'GenImage', 'results', timestr, fname))\n",
        "\n",
        "\n",
        "def train(train_loss, val_loss, train_acc, val_acc, best_model, epochs, learning_rate, train_accs, val_accs):\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9, last_epoch=-1, verbose=False)\n",
        "\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(epochs, config.epochs):\n",
        "        print('-------------------- EPOCH ' + str(epoch) + ' ---------------------')\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        epoch_accuracy = 0\n",
        "\n",
        "        for step, (inputs, labels) in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
        "\n",
        "            logits = model(inputs)\n",
        "\n",
        "            loss = criterion(logits, labels)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            acc, _ = compute_accuracy(logits, labels)\n",
        "            epoch_accuracy += acc\n",
        "\n",
        "            # Back-propogate\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        # Get train and val loss per batch\n",
        "        epoch_train_loss = epoch_loss / len(train_dataloader)\n",
        "        epoch_train_accuracy = epoch_accuracy / len(train_dataloader)\n",
        "        losses.append(epoch_train_loss)\n",
        "\n",
        "        epoch_val_loss, epoch_val_accuracy = val_model(val_dataloader, model)\n",
        "        val_losses.append(epoch_val_loss)\n",
        "\n",
        "        train_accs.append(epoch_train_accuracy)\n",
        "        val_accs.append(epoch_val_accuracy)\n",
        "\n",
        "        if not val_loss or min(epoch_val_loss, val_loss) == epoch_val_loss:\n",
        "            val_loss = epoch_val_loss\n",
        "            best_model = deepcopy(model.state_dict())\n",
        "        if not train_loss or min(train_loss, epoch_train_loss) == epoch_train_loss:\n",
        "            train_loss = epoch_train_loss\n",
        "        if not train_acc or max(train_acc, epoch_train_accuracy) == epoch_train_accuracy:\n",
        "            train_acc = epoch_train_accuracy\n",
        "        if not val_acc or max(val_acc, epoch_val_accuracy) == epoch_val_accuracy:\n",
        "            val_acc = epoch_val_accuracy\n",
        "\n",
        "        # Adjust learning rate scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "        print('Training Loss: ' + str(epoch_train_loss))\n",
        "        print('Validation Loss: ' + str(epoch_val_loss))\n",
        "        print('Training Accuracy: ' + str(epoch_train_accuracy))\n",
        "        print('Validation Accuracy: ' + str(epoch_val_accuracy))\n",
        "        print('---------------------------------------------')\n",
        "\n",
        "        # Save model and stats for checkpoints\n",
        "        save_model(best_model, 'latest_model')\n",
        "        epochs += 1\n",
        "        save_stats(train_loss, val_loss,train_acc, val_acc, epochs,\n",
        "                   scheduler.get_last_lr()[0], train_accs, val_accs)\n",
        "\n",
        "    # Save the model and plot the loss\n",
        "    plot_loss(losses, val_losses)\n",
        "    return train_loss, val_loss, train_acc, val_acc\n",
        "\n",
        "def save_experiment(statistics):\n",
        "    \"\"\"\n",
        "    Saves the experiment results to a csv\n",
        "    :param config: The hyperparameters used\n",
        "    :param statistics: The accuracies for the training, validation, and test sets\n",
        "    \"\"\"\n",
        "    trial_dict = {\n",
        "        'Model name': [timestr],\n",
        "        'Learning rate': [config.learning_rate],\n",
        "        'Weight decay': [config.weight_decay],\n",
        "        'Batch size': [config.batch_size],\n",
        "        'Epochs': [config.epochs],\n",
        "        'Min Training Loss': [statistics[0]],\n",
        "        'Min Validation Loss': [statistics[1]],\n",
        "        'Maximum Training Accuracy': [statistics[2]],\n",
        "        'Maximum Validation Accuracy': [statistics[3]],\n",
        "    }\n",
        "\n",
        "    trial_dict = pd.DataFrame(trial_dict)\n",
        "    trial_dict.to_csv(os.path.join('drive', 'MyDrive', 'GenImage', 'results',\n",
        "                                   timestr, 'results.csv'), index=False, header=True)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "    checkpoint_path = os.path.join('drive', 'MyDrive', 'GenImage', 'results', timestr)\n",
        "    print(f'All model checkpoints and training stats will be saved in {checkpoint_path}')\n",
        "\n",
        "\n",
        "    losses = []\n",
        "    val_losses = []\n",
        "    train_accs, val_accs = [], []\n",
        "    min_train_loss = None\n",
        "    min_val_loss = None\n",
        "    max_val_acc = None\n",
        "    max_train_acc = None\n",
        "    best_model = None\n",
        "    epochs_ran = 0\n",
        "\n",
        "\n",
        "    # Load processors and models\n",
        "    model = CLIPModel()\n",
        "    model.to(device)\n",
        "\n",
        "    # Load datasets\n",
        "    train_dset = ImageDataset()\n",
        "    val_dset = ImageDataset(\n",
        "        d_type = 'val'\n",
        "    )\n",
        "\n",
        "    # Create Dataloaders\n",
        "    train_dataloader = DataLoader(train_dset, shuffle=True, batch_size=config.batch_size)\n",
        "    val_dataloader = DataLoader(val_dset, shuffle=True, batch_size=config.batch_size,\n",
        "                                num_workers=config.num_workers)\n",
        "\n",
        "    # Load checkpoint if neccesary:\n",
        "    if config.load_checkpoint:\n",
        "\n",
        "        print('Loading model from ' + config.checkpoint_file)\n",
        "\n",
        "        # Load the model and stats from the checkpoint\n",
        "        model.load_state_dict(torch.load(os.path.join('drive', 'MyDrive', 'GenImage', 'results', config.checkpoint_file,\n",
        "                                                      'latest_model.pth')))\n",
        "        best_model = CLIPModel()\n",
        "        best_model.load_state_dict(torch.load(os.path.join('drive', 'MyDrive', 'GenImage', 'results', config.checkpoint_file,\n",
        "                                                          'latest_model.pth')))\n",
        "\n",
        "        with open(os.path.join('drive', 'MyDrive', 'GenImage', 'results', config.checkpoint_file, 'stats.json'), 'r') as f:\n",
        "            stats = json.load(f)\n",
        "\n",
        "        min_train_loss, min_val_loss, losses, val_losses, epochs_ran = stats['min train loss'], stats[\n",
        "            'min val loss'], stats['losses'], stats['val losses'], stats['epochs']\n",
        "        max_train_acc, max_val_acc = stats['max train acc'], stats['max val acc']\n",
        "        train_accs, val_accs = stats['training accuracies'], stats['val accuracies']\n",
        "\n",
        "        print(f'Minimum Training Loss: {min_train_loss}')\n",
        "        print(f'Training Losses: {losses}')\n",
        "        print(f'Minimum Validation Loss: {min_val_loss}')\n",
        "        print(f'Validation Losses: {val_losses}')\n",
        "        print(f'Training Accuracies: {train_accs}')\n",
        "        print(f'Validation Accuracies: {val_accs}')\n",
        "        print(f'Maximum Training Accuracy: {max_train_acc}')\n",
        "        print(f'Maximum Validation Accuracy: {max_val_acc}')\n",
        "        print(f'Epochs ran: {epochs_ran}')\n",
        "        timestr = config.checkpoint_file\n",
        "    else:\n",
        "        os.mkdir(os.path.join('drive', 'MyDrive', 'GenImage', 'results', timestr))\n",
        "        os.mkdir(os.path.join('drive', 'MyDrive', 'GenImage', 'results', timestr, 'Confusion Matrices'))\n",
        "\n",
        "    # If loading a checkpoint, use the learning rate from the last epoch\n",
        "    if config.load_checkpoint:\n",
        "        lr = stats['learning rate']\n",
        "    else:\n",
        "        lr = config.learning_rate\n",
        "\n",
        "    min_train_loss, min_val_loss, max_train_acc, max_val_acc = (\n",
        "        train(min_train_loss, min_val_loss, max_train_acc,\n",
        "              max_val_acc, best_model, epochs_ran, lr, train_accs, val_accs))\n",
        "    statistics = [min_train_loss, min_val_loss, max_train_acc, max_val_acc]\n",
        "    save_experiment(statistics)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUnwqHn8SRgq"
      },
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GeClhcgdlcGP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOVppf3rHHDkkTR2TWx6AvO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}