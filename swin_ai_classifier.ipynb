{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ca1aea0-044b-4d42-8134-370ce540aa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f534eee-cbca-4f2c-a9d2-9ce324570b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealFakeDataset(Dataset):\n",
    "    def __init__(self, data_folder):\n",
    "        self.data_folder = data_folder\n",
    "        self.classes = {'nature': 0, 'ai': 1}\n",
    "        self.image_files = []\n",
    "        self.labels = []\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "        for class_name, class_label in self.classes.items():\n",
    "            class_folder = os.path.join(self.data_folder, class_name)\n",
    "            for image_file in os.listdir(class_folder):\n",
    "                self.image_files.append(os.path.join(class_folder, image_file))\n",
    "                self.labels.append(class_label)\n",
    "\n",
    "        self.labels = np.array(self.labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_files[idx]\n",
    "        image = cv2.imread(image_path)\n",
    "        image = self.transform(image)\n",
    "\n",
    "        return image, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3a0b080-2fa4-4b53-b745-ecdb343bfa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwinVision(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SwinVision, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.swin = models.swin_v2_t(pretrained=True)\n",
    "        for param in self.swin.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.swin = nn.Sequential(self.swin, nn.Linear(1000, num_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.swin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4bd49b-5b7a-424c-a77f-eace2fc0f360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/1864], Loss: 0.6618, Accuracy: 0.6106\n",
      "Validation Loss: 0.5654, Validation Accuracy: 0.7093\n",
      "Epoch [1/5], Step [200/1864], Loss: 0.5547, Accuracy: 0.7148\n",
      "Validation Loss: 0.5227, Validation Accuracy: 0.7576\n",
      "Epoch [1/5], Step [300/1864], Loss: 0.5441, Accuracy: 0.7354\n",
      "Validation Loss: 0.4927, Validation Accuracy: 0.7719\n",
      "Epoch [1/5], Step [400/1864], Loss: 0.5078, Accuracy: 0.7573\n",
      "Validation Loss: 0.4754, Validation Accuracy: 0.7880\n",
      "Epoch [1/5], Step [500/1864], Loss: 0.4690, Accuracy: 0.7811\n",
      "Validation Loss: 0.4609, Validation Accuracy: 0.7907\n",
      "Epoch [1/5], Step [600/1864], Loss: 0.4921, Accuracy: 0.7730\n",
      "Validation Loss: 0.4591, Validation Accuracy: 0.7907\n",
      "Epoch [1/5], Step [700/1864], Loss: 0.4499, Accuracy: 0.7805\n",
      "Validation Loss: 0.4445, Validation Accuracy: 0.8005\n",
      "Epoch [1/5], Step [800/1864], Loss: 0.4631, Accuracy: 0.7824\n",
      "Validation Loss: 0.4262, Validation Accuracy: 0.8077\n",
      "Epoch [1/5], Step [900/1864], Loss: 0.4625, Accuracy: 0.7805\n",
      "Validation Loss: 0.4254, Validation Accuracy: 0.8050\n",
      "Epoch [1/5], Step [1000/1864], Loss: 0.4563, Accuracy: 0.7855\n",
      "Validation Loss: 0.4311, Validation Accuracy: 0.7961\n",
      "Epoch [1/5], Step [1100/1864], Loss: 0.4336, Accuracy: 0.8105\n",
      "Validation Loss: 0.4241, Validation Accuracy: 0.8041\n",
      "Epoch [1/5], Step [1200/1864], Loss: 0.4469, Accuracy: 0.7993\n",
      "Validation Loss: 0.4269, Validation Accuracy: 0.8041\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_classes = 2  # Replace with the actual number of classes\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SwinVision(num_classes=2).to(device) # Load the ResNet model\n",
    "num_epochs = 5\n",
    "batch_size = 16\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "# Define the data loaders\n",
    "train_dataset = RealFakeDataset(data_folder='imagenet_ai_small/ADM/train')\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = RealFakeDataset(data_folder='imagenet_ai_small/ADM/val')\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Training loop\n",
    "losses = []\n",
    "accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # Get the inputs and labels from the data loader\n",
    "        inputs, labels = data\n",
    "        labels = labels.long()\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        accuracy += (outputs.argmax(1) == labels).sum()\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # Print every 100 mini-batches\n",
    "            accuracy = accuracy/(batch_size*100)\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {running_loss/100:.4f}, Accuracy: {accuracy:.4f}')\n",
    "            losses.append(running_loss/100)\n",
    "            accuracies.append(accuracy)\n",
    "            running_loss = 0.0\n",
    "            # Evaluate the model on the validation set\n",
    "            model.eval()\n",
    "\n",
    "            val_loss = 0.0\n",
    "            val_accuracy = 0.0\n",
    "            with torch.no_grad():\n",
    "                for data in val_loader:\n",
    "                    inputs, labels = data\n",
    "                    labels = labels.long()\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    outputs = model(inputs)\n",
    "                    val_loss += criterion(outputs, labels).item()\n",
    "                    val_accuracy += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "            val_accuracy /= len(val_dataset)\n",
    "            val_losses.append(val_loss)\n",
    "            val_accuracies.append(val_accuracy)\n",
    "\n",
    "            print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "# Plot and save the training loss and accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(accuracies)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_plot.png')\n",
    "\n",
    "# Plot and save the validation loss and accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(val_losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Validation Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(val_accuracies)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Validation Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('validation_plot.png')\n",
    "\n",
    "model_path = 'resnet_model.pth'\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print('Training finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0319d3c4-1e03-46e7-9cd0-ae9c64528232",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
